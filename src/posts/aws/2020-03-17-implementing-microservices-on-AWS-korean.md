# Implementing Microservices on AWS 한글 번역

# AWS에서 마이크로 서비스 구현

##### August 2019

<br>
<br>

![aws](/posts/images/aws/aws-logo.png)

<br>
<br>

## Notices

고객은 본 문서에 수록된 정보에 대해 독자적인 평가를 내릴 책임이 있다. 본 문서: (a)는 정보 제공 목적만을 위한 것이며, (b)는 예고 없이 변경될 수 있는 현재의 AWS 제품 및 관행을 나타내며, (3) AWS와 그 계열사, 공급자 또는 사용허가자로부터 어떠한 약속이나 보증도 작성하지 않는다. AWS 제품 또는 서비스는 명시적이든 암시적이든 보증, 진술 또는 어떠한 종류의 조건도 없이 "있는 그대로" 제공된다. 고객에 대한 AWS의 책임과 책임은 AWS 계약에 의해 관리되며, 본 문서는 AWS와 고객 간의 계약의 일부도, 수정도 하지 않는다.


© 2019년 아마존 웹서비스 주식회사 또는 그 계열사. 무단 전재 금지


<br>

## Abstract

Microservices는 소프트웨어 개발에 대한 아키텍처 및 조직적 접근방식으로서, 구현 주기를 단축하고, 혁신과 소유권을 강화하고, 소프트웨어 애플리케이션의 유지성과 확장성을 개선하며, 팀이 각 팀과 독립적으로 작업할 수 있도록 지원하는 민첩한 접근방식을 사용하여 소프트웨어와 서비스를 제공하는 조직을 확장하는 것이다. 기타. 마이크로서비스 접근방식을 이용하여, 소프트웨어는 독립적으로 배치될 수 있는 잘 정의된 API를 통해 통신하는 작은 서비스로 구성되어 있다. 이러한 서비스는 소규모 자치 단체에 의해 소유된다. 이러한 민첩한 접근 방식은 조직을 성공적으로 확장하기 위한 핵심 요소이다.

고객이 마이크로 서비스를 구축할 때 우리가 관찰하는 세 가지 일반적인 패턴은 API 기반, 이벤트 기반, 데이터 스트리밍이다. 본 백서에서는 세 가지 접근방식을 모두 소개하고 마이크로 서비스의 공통 특성을 요약하고, 마이크로 서비스 구축의 주요 과제에 대해 논의하고, 제품 팀이 이러한 과제를 극복하기 위해 어떻게 Amazon Web Services(AWS)를 활용할 수 있는지를 설명한다.

<br>

## Introduction

마이크로서비스 아키텍처는 소프트웨어 엔지니어링에 대한 완전히 새로운 접근 방식이 아니라 다음과 같은 다양한 성공적이고 입증된 개념의 조합이다.
- 신속한 소프트웨어 개발
- 서비스 지향 아키텍처
- API 우선 설계
- 지속적인 통합/지속적인 제공(CI/CD)

많은 경우 [Twelve-Factor App](https://12factor.net/)의 설계 패턴은 마이크로 서비스에 활용된다.

우리는 먼저 확장성이 뛰어나고 내결함성이 뛰어난 마이크로 서비스 아키텍처(사용자 인터페이스, 마이크로서비스 구현 및 데이터 저장소)와 컨테이너 기술을 활용하여 AWS에 구축하는 방법을 설명한다. 그런 다음 운영 복잡성을 줄이기 위해 일반적인 서버리스 마이크로 서비스 아키텍처를 구현하기 위해 AWS 서비스를 권장한다.

서버리스(Serverless)는 다음 원칙에 의해 운영 모델로 정의된다.
- 프로비저닝 또는 관리할 인프라 없음
- 소비 단위에 따른 자동 확장
- "가치 요금" 청구 모델
- 내장 가용성 및 내결함성

마지막으로, 우리는 전체 시스템을 살펴보고 분산 모니터링 및 감사, 데이터 일관성 및 비동기 통신과 같은 마이크로 서비스 아키텍처의 교차 서비스 측면에 대해 논의한다.

<br>

## Simple Microservices Architecture on AWS(AWS의 단순한 마이크로서비스 아키텍처)

일반적인 단일 애플리케이션은 UI(사용자 인터페이스) 계층, 비즈니스 계층 및 지속성 계층과 같은 다른 계층을 사용하여 구축된다. 마이크로 서비스 아키텍처의 중심 아이디어는 기능성을 기술적 계층에 의해가 아니라 특정한 구현에 의해 응집력 있는 "수직적"으로 나누는 것이다.

도메인. 그림 1은 AWS의 일반적인 마이크로서비스 응용 프로그램에 대한 참조 아키텍처를 보여준다.

![aws](/posts/images/aws/aws-2020-03-17-01.jpg)
그림 1: AWS의 일반적인 마이크로 서비스 애플리케이션

<br>

### User Interface

현대의 웹 애플리케이션은 종종 JavaScript 프레임워크를 사용하여 REST(Resignational State Transfer) 또는 RESTful API와 통신하는 단일 페이지 애플리케이션을 구현한다. 정적 웹 콘텐츠는 Amazon Simple Storage Service([Amazon S3](https://aws.amazon.com/ko/s3/)와 [Amazon CloudFront](https://aws.amazon.com/ko/cloudfront/)를 사용하여 제공할 수 있다.

마이크로 서비스의 클라이언트는 가장 가까운 엣지 로케이션에서 제공되며 캐쉬나 원본에 최적화된 연결을 가진 프록시 서버로부터 응답을 받기 때문에 대기 시간을 크게 줄일 수 있다. 그러나 서로 가까이서 운영되는 마이크로 서비스는 CDN의 혜택을 받지 못한다. 경우에 따라 이 접근법은 실제로 지연 시간이 늘어날 수 있다. 최선의 방법은 잡담(chattiness)을 줄이고 지연 시간을 최소화하기 위해 다른 캐싱 메커니즘을 구현하는 것이다.

<br>

### Microservices
우리는 종종 API가 마이크로서비스의 현관이라고 말한다. 즉, API가 일련의 프로그래밍 인터페이스(일반적으로 RESTful 웹 서비스 API) 뒤에 있는 애플리케이션 로직의 진입점 역할을 한다는 것이다. 이 API는 클라이언트로부터의 호출을 수용하고 처리하며, 트래픽 관리, 요청 필터링, 라우팅, 캐싱, 인증 및 권한 부여와 같은 기능을 구현할 수 있다.

#### Microservices Implementations

AWS는 마이크로 서비스의 개발을 지원하는 통합형 빌딩 블록을 가지고 있다. 두 가지 일반적인 접근방식은 [AWS Lambda](https://aws.amazon.com/ko/lambda/)와 [AWS Fargate](https://aws.amazon.com/ko/fargate/)과 함께 Docker 컨테이너를 사용하는 것이다.

AWS Lambda를 사용하면 코드를 업로드하고 Lambda가 실행 및 실행 확장에 필요한 모든 작업을 처리하여 고가용성(HA)으로 실제 수요 곡선을 충족할 수 있도록 할 수 있다. 인프라 관리가 필요 없다는 이야기이다. Lambda는 여러 프로그래밍 언어를 지원하며 다른 AWS 서비스에서 트리거되거나 웹 또는 모바일 애플리케이션에서 직접 호출될 수 있다. AWS Lambda의 가장 큰 장점 중 하나는 보안과 확장이 AWS에 의해 관리되기 때문에 비즈니스 로직에 집중할 수 있다는 것이다. 람다의 독단적인 접근법이 확장 가능한 플랫폼으로 이끈다.

개발를 위한 운영 노력을 줄이기 위한 일반적인 접근방식은 컨테이너 기반 구축이다. [Docker](https://www.docker.com/)과 같은 컨테이너 기술은 휴대성, 생산성, 효율성과 같은 이점 때문에 지난 몇 년 동안 인기가 증가했다. 컨테이너가 있는 학습 곡선은 가파를 수 있으며, 도커 이미지 및 모니터링에 대한 보안 해결 방법을 생각해야 한다. [Amazon ECS](https://aws.amazon.com/ko/ecs/)(Amazon Elastic Container Service) 및 [Amazon EKS](https://aws.amazon.com/ko/eks/)(Amazon Elastic Kubernetes Service)는 클러스터 관리 인프라를 설치, 운영 및 확장할 필요가 없다. 간단한 API 호출을 통해 Docker 지원 애플리케이션을 시작하고 중지하고, 클러스터의 전체 상태를 쿼리하며, 보안 그룹, 로드 밸런싱, [Amazon EBS](https://aws.amazon.com/ko/ebs/)(Amazon Elastic Block Store) 볼륨 및 [AWS Identity and Access Management(IAM)](https://aws.amazon.com/ko/iam/) 역할과 같은 친숙한 많은 기능에 액세스할 수 있다.

AWS Fargate는 컨테이너를 실행하기 위해 가상 머신의 클러스터를 프로비저닝, 구성 및 확장할 염려가 없도록 서버리스 컨테이너를 실행할 수 있는 컨테이너 관리 서비스이다. Fargate를 사용하면 컨테이너 애플리케이션에 충분한 컴퓨팅 리소스를 프로비저닝하는 것에 대해 더 이상 걱정할 필요가 없다. Fargate는 수만 개의 컨테이너를 출시하고 가장 미션 크리티컬한 애플리케이션을 실행할 수 있도록 쉽게 확장할 수 있다.

Amazon ECS는 컨테이너 배치 전략과 제약 조건을 지원하여 Amazon ECS가 작업을 배치하고 종료하는 방법을 사용자 정의한다. 태스크 배치 제약조건은 태스크 배치 중에 고려되는 규칙이다. 속성(기본적으로 키-값 쌍)을 컨테이너 인스턴스에 연결한 다음 제약 조건을 사용하여 이러한 속성을 기반으로 태스크를 배치할 수 있다. 예를 들어, GPU로 구동되는 인스턴스와 같은 인스턴스 유형이나 인스턴스 능력에 따라 특정 마이크로 서비스를 배치할 수 있다.

Amazon EKS는 오픈소스 쿠버네츠 소프트웨어의 최신 버전을 실행하므로, 쿠버네츠 커뮤니티의 모든 기존 플러그인과 툴링을 사용할 수 있다. Amazon EKS에서 실행 중인 애플리케이션은 사내 데이터 센터나 퍼블릭 클라우드에서 실행되는 표준 Kubernetes 환경에서 실행되는 애플리케이션과 완벽하게 호환된다. Amazon EKS는 IAM을 Kubernetes와 통합하여 IAM 엔티티를 Kubernetes의 네이티브 인증 시스템에 등록할 수 있게 한다. Kubernetes 마스터를 인증하기 위한 자격 증명을 수동으로 설정할 필요는 없다. IAM 통합을 통해 IAM을 사용하여 마스터 자체와 직접 인증함으로써 Kubernetes 마스터의 공용 엔드포인트에 대한 세부적인 액세스 권한을 제공할 수 있다.

Amazon ECS 및 Amazon EKS에서 사용되는 도커 이미지는 Amazon Elastic Container Registry(Amazon ECR)에 저장될 수 있다. Amazon ECR은 컨테이너 레지스트리에 전원을 공급하기 위해 필요한 인프라를 운영하고 확장할 필요가 없다.
지속적인 통합과 지속적인 제공(CI/CD)은 시스템 안정성과 보안을 유지하면서 빠른 소프트웨어 변경을 가능하게 하는 DevOps 이니셔티브의 핵심이자 모범 사례다. 그러나 이는 본 백서의 범위 밖이며, "AWS의 지속적인 통합 및 지속적인 제공" 백서에서 더 많은 정보를 찾을 수 있다.

#### Private Links
[AWS PrivateLink](https://aws.amazon.com/ko/privatelink/)는 지원되는 AWS 서비스, 다른 AWS 계정(VPC 엔드포인트 서비스)에서 호스팅하는 서비스, AWS Marketplace 파트너 서비스에 VPC를 개인적으로 연결할 수 있는 가용성과 확장성이 뛰어난 기술이다. 서비스와 통신하기 위해 인터넷 게이트웨이, NAT 장치, 공용 IP 주소, [AWS Direct Connect](https://aws.amazon.com/ko/directconnect/) 연결 또는 VPN 연결이 필요하지 않다. VPC와 서비스 간의 트래픽은 Amazon 네트워크를 떠나지 않는다.

PrivateLink는 마이크로 서비스 아키텍처의 분리를 증가시키는 훌륭한 방법이다. 예를 들어, 각 마이크로 서비스를 호스팅하고 단일 마이크로 서비스를 제공하는 수백 개의 VPC를 생성할 수 있다. 회사들은 이제 개인 연결을 통해 접속할 수 있도록 서비스를 만들어 다른 AWS 고객들에게 판매를 위해 제공할 수 있다. TCP 트래픽을 수용하고 네트워크 로드 밸런서 뒤에 호스팅한 다음 직접 또는 AWS 마켓플레이스에서 서비스를 사용할 수 있도록 하는 서비스를 생성한다. 그들은 새로운 가입 요청을 통지 받을 것이고 각각의 애플리케이션를 받아들이거나 거절할 수 있다. AWS의 힘은
PrivateLink는 모든 시나리오에서 장점이 있으며, 특히 SaaS 조직에게 관심이 있다. AWS PrivateLink를 통해 SaaS 사업자는 이 네트워킹 구조를 사용하여 솔루션의 아키텍처 및 비즈니스 모델을 개선하고 확장할 수 있는 새롭고 창의적인 기회를 본다.

<br>

### Data Store

데이터 저장소는 마이크로 서비스에 필요한 데이터를 유지하는 데 사용된다. 세션 데이터의 일반적인 저장소는 Memcached 또는 Redis와 같은 메모리 내 캐시다. AWS는 관리형 [Amazon ElastiCache](https://aws.amazon.com/ko/elasticache/) 서비스의 일부로 두 가지 기술을 모두 제공한다.

애플리케이션 서버와 데이터베이스 사이에 캐시를 두는 것은 데이터베이스에 대한 읽기 로드를 줄이기 위한 일반적인 메커니즘이며, 이는 다시 더 많은 쓰기를 지원하기 위해 자원을 사용할 수 있게 할 수 있다. 또한 캐시는 대기 시간을 단축시킬 수 있다.

관계형 데이터베이스는 구조화된 데이터와 비즈니스 개체를 저장하는 데 여전히 매우 인기가 있다. AWS는 Amazon Relational Database Service([Amazon RDS](https://aws.amazon.com/ko/rds/))를 통해 6개의 데이터베이스 엔진(Microsoft SQL Server, Oracle, MySQL, MariaDB, Postgre, [Amazon Aurora](https://aws.amazon.com/ko/rds/aurora/))을 관리 서비스로 제공한다. 

그러나 관계형 데이터베이스는 무한 확장용으로 설계되지 않아 많은 수의 쿼리를 지원하기 위해 기법을 적용하기가 어렵고 시간이 많이 소요될 수 있다.

NoSQL 데이터베이스는 관계형 데이터베이스의 일관성에 비해 확장성, 성능 및 가용성을 선호하도록 설계되었다. NoSQL 데이터베이스의 한 가지 중요한 요소는 일반적으로 엄격한 스키마를 시행하지 않는다는 것이다. 데이터는 수평으로 확장될 수 있는 파티션에 분산되어 있으며 파티션 키를 사용하여 검색된다.

개별 마이크로 서비스는 한 가지를 잘 수행하도록 설계되었기 때문에 일반적으로 NoSQL 지속성에 적합할 수 있는 단순화된 데이터 모델을 가지고 있다. NoSQL-database는 관계형 데이터베이스와 다른 접근 패턴을 가지고 있다는 것을 이해하는 것이 중요하다. 예를 들어, 테이블을 결합하는 것은 불가능하다. 이것이 필요하다면, 그 로직은 애플리케이션에 구현되어야 한다. [Amazon DynamoDB](https://aws.amazon.com/ko/dynamodb/)를 사용하여 원하는 양의 데이터를 저장하고 검색할 수 있으며 요청 트래픽을 처리할 수 있는 데이터베이스 테이블을 만들 수 있다. DynamoDB는 한 자리 수 밀리초의 성능을 제공하지만, 응답 시간을 마이크로초 단위로 요구하는 특정 사용 사례도 있다. [DAX(DynamoDB Accelerator)](https://aws.amazon.com/ko/dynamodb/dax/)는 데이터 액세스를 위한 캐싱 기능을 제공한다.

DynamoDB는 또한 실제 트래픽에 대응하여 처리량을 동적으로 조정할 수 있는 자동 확장 기능을 제공한다. 그러나 애플리케이션에서 짧은 기간 동안 급증하는 대규모 활동으로 인해 용량 계획이 어렵거나 불가능한 경우가 있다. 이러한 상황에 대해 DynamoDB는 요청 당 지불 가격을 제공하는 온디맨드 옵션을 제공한다. DynamoDB 온디맨드 기능은 용량 계획 없이 초당 수천 개의 요청을 즉시 처리할 수 있다.

<br>

## Reducing Operational Complexity(운영 복잡성 감소)

우리가 설명한 아키텍처는 이미 관리형 서비스를 사용하고 있지만, 우리는 여전히 Amazon Elastic Compute Cloud([Amazon EC2](https://aws.amazon.com/ko/ec2/)) 인스턴스를 관리해야 한다. 우리는 완전한 서버리스 아키텍처를 사용하여 마이크로 서비스를 실행, 유지 및 모니터링하는 데 필요한 운영 노력을 더욱 줄일 수 있다.

### API Implementation
API의 설계, 구축, 모니터링, 지속적인 개선 및 유지관리는 많은 시간이 소요되는 작업이 될 수 있다. 때때로 모든 클라이언트의 역호환성을 보장하기 위해 서로 다른 버전의 API를 실행해야 한다. 개발 주기의 여러 단계(즉, 개발, 시험, 생산)는 운영 노력을 더욱 배가시킨다.

권한 부여는 모든 API에 있어 중요한 기능이지만, 일반적으로 구축이 복잡하고 반복적인 작업을 수반한다. API가 공표되어 성공하게 되면, 다음 과제는 API를 활용하는 제3자 개발자의 생태계를 관리, 감시, 자본화하는 것이다.
다른 중요한 기능 및 과제는 백엔드 서비스를 보호하기 위한 요청 제한, API 응답 캐싱, 요청 및 응답 변환 처리, 스웨거와 같은 툴을 사용한 API 정의 및 문서 생성 등이다.

[Amazon API Gateway](https://aws.amazon.com/ko/api-gateway/)는 이러한 문제를 해결하고 RESTful API 생성 및 유지관리의 운영 복잡성을 줄인다. API Gateway를 사용하면 AWS API 또는 AWS Management Console을 사용하여 Swagger 정의를 가져와 프로그래밍 방식으로 API를 생성할 수 있다. API Gateway는 Amazon EC2, Amazon ECS, AWS Lambda 또는 사내 환경에서 실행되는 모든 웹 애플리케이션에 대한 현관 역할을 한다. 기본적으로 API Gateway를 사용하면 서버를 관리할 필요 없이 API를 실행할 수 있다.

그림 2는 API Gateway가 API 호출을 처리하고 다른 구성 요소와 상호 작용하는 방법을 보여준다. 모바일 기기, 웹 사이트 또는 기타 백엔드 서비스의 요청은 지연 시간을 최소화하고 최적의 사용자 환경을 제공하기 위해 가장 가까운 CloudFront Point(PoP)로 라우팅된다.

![aws](/posts/images/aws/aws-2020-03-17-02.jpg)
그림 2: API 게이트웨이 통화 흐름

<br>

### Serverless Microservices

"서버가 없는 것보다 관리하기 쉬운 서버는 없다." 서버를 제거하는 것은 운영상의 복잡성을 제거하는 좋은 방법이다.

![aws](/posts/images/aws/aws-2020-03-17-03.jpg)
그림 3: AWS Lambda를 사용한 서버리스 마이크로서비스

Lambda는 API Gateway와 긴밀하게 통합되어 있다. API Gateway에서 Lambda로 동기식 호출을 할 수 있는 기능을 통해 완전한 서버리스 애플리케이션을 만들 수 있으며, 이 문서에 자세히 설명되어 있다.

그림 3은 AWS Lambda를 이용한 서버리스 마이크로 서비스의 아키텍처를 보여주고 있는데, AWS Lambda는 확장 및 고가용성을 위한 설계에 대한 아키텍처 부담을 없애고 마이크로 서비스 기반 인프라의 실행 및 모니터링을 위한 운영 노력을 제거한다.

그림 4는 서버리스 서비스에 기반한 유사한 구현을 보여준다. 이 아키텍처에서 도커 컨테이너는 AWS Fargate와 함께 사용되므로 기본 인프라에 신경 쓸 필요가 없다. Amazon DynamoDB 외에도, [Amazon Aurora Serverless](https://aws.amazon.com/ko/rds/aurora/serverless/)가 사용되는데, 이것은 Amazon Aurora(MySQL 호환 에디션)의 온디맨드 자동 스케일링 구성으로서, 당신의 어플리케이션 요구에 따라 데이터베이스가 자동으로 시작, 종료 및 용량 확장/축소된다.

![aws](/posts/images/aws/aws-2020-03-17-04.jpg)
그림 4: AWS Fargate를 사용한 서버리스 마이크로서비스

<br>

### Deploying Lambda-Based Applications
[AWS CloudFormation](https://aws.amazon.com/ko/cloudformation/)을 사용하여 서버리스 애플리케이션을 정의, 배포 및 구성할 수 있다.
AWS 서버리스 애플리케이션 모델([AWS SAM](https://github.com/awslabs/serverless-application-model))은 서버리스 애플리케이션을 정의하는 편리한 방법이다. AWS SAM은 기본적으로 CloudFormation에서 지원되며 서버리스 리소스를 표현하기 위한 간단한 구문을 정의한다. 애플리케이션을 배포하려면, CloudFormation 템플릿에 연결된 사용 권한 정책과 함께 애플리케이션의 일부로 필요한 리소스를 지정하고 배포 아티팩트를 패키징하고 템플릿을 배포하십시오. AWS SAM을 기반으로 하는 SAM Local은 서버리스 애플리케이션을 Lambda 런타임에 업로드하기 전에 로컬에서 개발, 테스트 및 분석할 수 있는 환경을 제공하는 AWS CLI 툴이다. SAM Local을 사용하여 AWS 런타임 환경을 시뮬레이션하는 로컬 테스트 환경을 만들 수 있다.

<br>

## Distributed Systems Components(분산 시스템 구성 요소)
AWS가 개별 마이크로 서비스와 관련된 과제를 어떻게 해결할 수 있는지 살펴본 후, 우리는 이제 서비스 검색, 데이터 일관성, 비동기 통신, 분산 모니터링 및 감사와 같은 서비스 간 과제에 초점을 맞추고자 한다.

### Service Discovery(서비스 검색)
마이크로 서비스 아키텍처의 주요 과제 중 하나는 서비스가 서로 발견하여 상호작용을 할 수 있도록 하는 것이다. 마이크로서비스 아키텍처의 분산된 특성은 서비스가 통신하는 것을 더 어렵게 할 뿐만 아니라, 그러한 시스템의 상태를 확인하고 새로운 애플리케이션을 사용할 수 있게 될 때 발표하는 것과 같은 다른 문제를 제시한다. 또한 애플리케이션에서 사용할 수 있는 구성 데이터와 같은 메타 스토어 정보를 저장하는 방법과 위치를 결정해야 한다. 이 섹션에서는 마이크로 서비스 기반 아키텍처에 대한 AWS에서 서비스 검색을 수행하기 위한 몇 가지 기법을 탐구한다.

#### DNS-Based Service Discovery(DNS 기반 서비스 검색)
이제 Amazon ECS에는 컨테이너형 서비스가 검색하여 서로 쉽게 연결할 수 있는 통합 서비스 검색 기능이 포함되어 있다.
이전에는 서비스가 서로 검색하여 연결할 수 있도록 하기 위해 [Amazon Route 53](https://aws.amazon.com/ko/route53/), AWS Lambda, ECS Event Stream에 기반한 자신의 서비스 검색 시스템을 구성하여 실행하거나 모든 서비스를 로드 밸런서에 연결해야 했다.

Amazon ECS는 Route 53 Auto Naming API를 사용하여 서비스 이름 레지스트리를 생성하고 관리한다. 이름은 자동으로 DNS 레코드 집합에 매핑되므로, 당신은 당신의 코드에 있는 이름으로 서비스를 참조하고, 런타임에 서비스의 엔드포인트으로 이름을 결정하기 위해 DNS 쿼리를 작성할 수 있다. 서비스의 작업 정의에 상태 점검 조건을 지정할 수 있으며 Amazon ECS는 서비스 조회를 통해 건강한 서비스 엔드포인트만 반환되도록 보장한다.

또한 Kubernetes가 관리하는 서비스에 대한 통합 서비스 검색도 활용할 수 있다. 이러한 통합을 가능하게 하기 위해 AWS는 Kubernetes 인큐베이터 프로젝트인 외부 DNS 프로젝트에 기여했다.

또 다른 옵션은 [AWS Cloud Map](https://aws.amazon.com/ko/cloud-map/)의 기능을 활용하는 것이다. AWS 클라우드 맵은 IP, URL, ARN 등의 리소스에 대한 서비스 레지스트리를 제공하고, 검색된 리소스 집합을 좁히기 위해 속성을 사용할 수 있는 API 기반 서비스 검색 메커니즘을 제공하여 자동 명명 API의 기능을 확장한다. 기존 Route 53 자동 명명 리소스는 AWS 클라우드 맵으로 자동 업그레이드된다.

#### Third-party software(타사 소프트웨어)
서비스 검색을 구현하는 다른 접근방식은 [HashiCorp Consul](https://www.consul.io/), [etcd](https://github.com/etcd-io/etcd), 또는 [Netflix Eureka](https://github.com/Netflix/eureka)과 같은 타사 소프트웨어를 사용하는 것이다. 이 세 가지 예는 모두 배포되고 신뢰할 수 있는 키-값 저장소를 말한다. HashiCorp Consul의 경우 유연하고 확장 가능한 AWS 클라우드 환경을 설정하고 원하는 구성으로 HashiCorp Consul을 자동으로 시작하는 [AWS Quick Start](https://aws.amazon.com/ko/quickstart/architecture/consul/)가 있다.

#### Service Meshes(서비스 메시)
첨단 마이크로 서비스 아키텍처에서 실제 애플리케이션은 수백 또는 수천 개의 서비스로 구성될 수 있다. 종종 애플리케이션의 가장 복잡한 부분은 실제 서비스 자체가 아니라 그 서비스 간의 통신이다. 서비스 메시는 서비스 간 통신을 처리하기 위한 추가적인 계층으로, 마이크로 서비스 아키텍처의 트래픽 모니터링과 제어를 담당한다. 이를 통해 서비스 검색과 같은 작업이 이 계층에 의해 완전히 처리될 수 있다.

일반적으로 서비스 메시는 데이터 평면과 제어 평면으로 분할된다. 데이터 평면은 애플리케이션 코드를 마이크로 서비스 사이의 모든 네트워크 통신을 가로채는 특수 사이드카 프록시로 배치되는 지능형 프록시 세트로 구성된다. 제어면은 프록시와 통신할 책임이 있다.

서비스 메시는 투명하며, 이는 애플리케이션 개발자들이 이 추가 계층을 인식할 필요가 없으며 기존 애플리케이션 코드를 변경할 필요가 없다는 것을 의미한다. [AWS App Mesh](https://aws.amazon.com/ko/app-mesh/)는 애플리케이션 수준의 네트워킹을 제공하여 여러 유형의 컴퓨팅 인프라에서 서비스가 서로 쉽게 통신할 수 있도록 하는 서비스 메시 입니다. App Mesh는 서비스 통신 방식을 표준화하여 엔드 투 엔드 가시성을 제공하고 애플리케이션의 고가용성을 보장한다.

AWS App Mesh는 AWS Fargate, Amazon ECS, Amazon EKS, AWS에서 실행되는 기존 또는 새로운 마이크로 서비스와 함께 사용할 수 있으며, AWS에서는 자체 관리 Kubernetes를 사용할 수 있다. App Mesh는 코드 변경 없이 단일 애플리케이션으로 클러스터, 오케스트레이션 시스템 또는 VPC에서 실행되는 마이크로 서비스에 대한 통신을 모니터링하고 제어할 수 있다.

<br>

### Distributed Data Management(분산 데이터 관리)

단일 애플리케이션은 일반적으로 모든 애플리케이션 구성 요소에 공통되는 단일 데이터 모델을 정의하는 대규모 관계형 데이터베이스를 기반으로 한다. 마이크로서비스 접근법에서 그러한 중앙 데이터베이스는 분산형 및 독립형 구성요소의 구축 목표를 방지할 수 있다. 각 마이크로 서비스 구성요소는 고유의 데이터 지속성 계층을 가져야 한다.

그러나 분산된 데이터 관리는 새로운 과제를 제기한다. [CAP 이론](https://en.wikipedia.org/wiki/CAP_theorem)의 결과로서 분산된 마이크로 서비스 아키텍처는 본질적으로 성능의 일관성을 상쇄하고 궁극적인 일관성을 수용해야 한다.

분산형 시스템에서, 사업 거래는 여러 마이크로 서비스에 걸쳐 이루어질 수 있다. 그들이 단일 [ACID](https://en.wikipedia.org/wiki/ACID) 거래를 이용할 수 없기 때문에, 당신은 부분적인 실행으로 끝날 수 있다. 이 경우, 우리는 이미 처리된 거래를 다시 할 수 있는 통제 로직이 필요할 것이다. 이를 위해 분산된 [Saga 패턴](https://theburningmonk.com/2017/07/applying-the-saga-pattern-with-aws-lambda-and-step-functions/)을 일반적으로 사용한다. 사업거래가 실패하는 경우, Saga에서는 앞의 거래에 의해 이루어진 변경을 취소하는 일련의 보상거래를 조직한다. [AWS Step Functions](https://aws.amazon.com/ko/step-functions/)을 사용하면 다음 그림과 같이 Saga 실행 코디네이터를 쉽게 구현할 수 있다.

![aws](/posts/images/aws/aws-2020-03-17-05.jpg)
그림 5: Saga 실행 코디네이터

마스터 데이터 관리 도구 및 절차에 의해 처리된 중요한 참조 데이터의 중앙 집중식 저장소를 구축하면 마이크로 서비스가 중요한 데이터를 동기화하고 롤백할 수 있는 수단을 제공한다. 예약된 Amazon CloudWatch 이벤트와 함께 Lambda를 사용하면 간단한 정리 및 중복제거 메커니즘을 구축할 수 있다.

상태 변화가 단일 마이크로 서비스 이상에 영향을 미치는 것은 매우 흔한 일이다. 이러한 경우, 이벤트 소싱은 유용한 패턴으로 입증되었다. 이벤트 소싱의 핵심 아이디어는 모든 애플리케이션 변경을 이벤트 레코드로 표현하고 유지하는 것이다. 응용 프로그램 상태를 유지하는 대신 데이터는 일련의 이벤트로 저장된다. 데이터베이스 트랜잭션 기록과 버전 제어 시스템은 이벤트 소싱에 대해 잘 알려진 두 가지 예다. 이벤트 소싱에는 몇 가지 이점이 있다: 상태를 어느 시점에서도 결정하고 재구성할 수 있다. 그것은 자연스럽게 지속적인 감사 추적을 생성하고 디버깅을 용이하게 한다.
마이크로서비스 아키텍처의 맥락에서, 이벤트 소싱은 게시/구독 패턴을 사용하여 애플리케이션의 다른 부분을 디커플링할 수 있으며, 동일한 이벤트 데이터를 별도의 마이크로서비스를 위한 다른 데이터 모델에 공급한다. 이벤트 소싱은 CQRS(명령 쿼리 책임 분리) 패턴과 함께 자주 사용되어 쓰기 작업 부하에서 읽기를 분리하고 성능, 확장성 및 보안을 위해 최적화된다. 기존 데이터 관리 시스템에서 명령과 쿼리를 동일한 데이터 저장소에 대해 실행한다.

그림 6은 이벤트 소싱 패턴을 AWS에서 구현할 수 있는 방법을 보여준다. [Amazon Kinesis Data Streams](https://aws.amazon.com/ko/kinesis/data-streams/)은 응용 프로그램 변경을 이벤트로 캡처하여 Amazon S3에서 유지하는 중앙 이벤트 저장소의 주요 구성 요소 역할을 한다.
그림 6은 Amazon API Gateway, AWS Lambda 및 Amazon DynamoDB로 구성된 세 개의 서로 다른 마이크로 서비스를 보여준다. 파란색 화살표는 이벤트의 흐름을 나타낸다. 마이크로서비스 1은 이벤트 상태 변화를 경험할 때 Kinesis 데이터 스트림에 메시지를 작성하여 이벤트를 게시한다. 모든 마이크로 서비스는 AWS Lambda에서 자체 Kinesis Data Streams 애플리케이션을 실행하며, 메시지 사본을 읽고, 마이크로 서비스에 대한 관련성에 따라 필터링하며, 추가 처리를 위해 전달할 수 있다.

![aws](/posts/images/aws/aws-2020-03-17-06.jpg)
그림 6: AWS의 이벤트 소싱 패턴

Amazon S3는 모든 마이크로 서비스에 모든 이벤트를 지속적으로 저장하며 디버깅, 응용 프로그램 상태 복구 또는 응용 프로그램 변경에 관한 한 진실의 단일 원천이다.

<br>

### Asynchronous Communication and Lightweight Messaging(비동기 통신 및 경량 메시징)
전통적인 단일 애플리케이션에서의 통신은 간단하다. 애플리케이션의 한 부분은 메소드 호 또는 내부 이벤트 배포 메커니즘을 사용한다. 전통적인 단일 애플리케이션에서의 통신은 간단하다. 애플리케이션의 한 부분은 메소드 호 또는 내부 이벤트 배포 메커니즘을 사용하여 o와 통신한다.부품들 동일한 애플리케이션이 디커플링된 마이크로 서비스를 사용하여 구현되는 경우, 애플리케이션 각 부분 간의 통신은 네트워크 통신을 사용하여 구현해야 한다.

REST 기반 통신
HTTP/S 프로토콜은 마이크로 서비스 간에 동기식 통신을 구현하는 가장 인기 있는 방법이다. 대부분의 경우 RESTful API는 HTTP를 전송 계층으로 사용한다. REST 아키텍처 스타일은 상태 비저장 통신, 균일한 인터페이스 및 표준 방법에 의존한다.
API Gateway를 사용하면 애플리케이션이 Amazon EC2 및 Amazon ECS에서 실행되는 워크로드, Lambda에서 실행되는 코드 또는 웹 애플리케이션과 같은 백엔드 서비스에서 데이터, 비즈니스 로직 또는 기능에 액세스할 수 있는 API를 만들 수 있다. API Gateway 서비스로 정의된 API 개체는 리소스 및 메서드의 그룹이다.

자원은 API의 도메인 내에 입력된 개체로서 데이터 모델이나 관계를 다른 자원과 연관시켰을 수 있다. 각 자원은 하나 이상의 방법, 즉 GET, POST 또는 PUT와 같은 표준 HTTP 동사에 응답하도록 구성할 수 있다. REST API는 새로운 버전으로 복제될 뿐만 아니라 다른 단계로 배포될 수 있다.

API Gateway는 트래픽 관리, 권한 부여 및 액세스 제어, 모니터링 및 API 버전 관리를 포함하여 최대 수십만 개의 동시 API 호출을 수신 및 처리하는 데 관련된 모든 작업을 처리한다.

비동기 메시징 및 이벤트 전달
마이크로 서비스 간의 통신을 구현하기 위한 추가적인 패턴은 메시지 전달이다. 서비스는 대기열을 통해 메시지를 교환하여 통신한다. 이러한 의사소통 방식의 한 가지 주요 이점은 서비스 검색이 필요하지 않으며 서비스는 느슨한 커플이라는 것이다.
동기식 시스템은 밀접하게 결합되어 있는데, 이는 동기식 다운스트림 의존성의 문제가 업스트림 호출자에게 즉각적인 영향을 미친다는 것을 의미한다. 업스트림 콜러에서 재시도하면 문제를 빠르게 부채질하고 증폭시킬 수 있다.

프로토콜과 같은 특정 요구사항에 따라 AWS는 이 패턴을 구현하는 데 도움이 되는 다양한 서비스를 제공한다. 하나의 가능한 구현은 Amazon Simple Queue Service(Amazon SQS44)와 Amazon Simple Notification Service(Amazon SNS45)의 조합을 사용한다.

아마존 sns는 응용 프로그램이 푸시 메커니즘을 통해 여러 가입자에게 메시지를 보낼 수 있도록 한다. 아마존 sns와 아마존 SQS를 함께 사용하면 하나의 메시지가 여러 소비자에게 전달될 수 있다. 그림 7은 아마존 sns와 아마존 SQS의 통합을 보여준다.


![aws](/posts/images/aws/aws-2020-03-17-07.jpg)
그림 7: AWS의 메시지 버스 패턴

SNS 항목에 SQS 큐를 구독하면 해당 항목에 메시지를 게시할 수 있으며 아마존 SNS는 가입한 SQS 큐에 메시지를 전송한다. 메시지에는 JSON 형식의 메타데이터 정보와 함께 주제에 게시된 제목과 메시지가 포함되어 있다.

기존 소프트웨어가 JMS, NMS, AMQP, STOMP, MQTT, WebSocket 등 메시징에 개방형 표준 API와 프로토콜을 사용하는 경우에 사용할 수 있는 Amazon MQ46에 기반한 다른 구현 전략이다. Amazon SQS는 사용자 지정 API를 공개하는데, 이는 사내 환경(예: AWS)에서 AWS로 마이그레이션하려는 기존 애플리케이션이 있는 경우 코드 변경이 필요하다는 것을 의미한다. 아마존 MQ와 함께 이것은 많은 경우에 필요하지 않다.

아마존 MQ는 인기 오픈소스 메시지 브로커인 액티브MQ의 관리 및 유지관리를 관리한다. 기본 인프라는 애플리케이션의 안정성을 지원하기 위해 고가용성 및 메시지 내구성을 위해 자동으로 프로비저닝된다.

오케스트레이션 및 상태 관리
마이크로서비스의 분산된 특성은 다중 마이크로서비스가 관련되었을 때 워크플로우를 조정하는데 어려움을 준다. 개발자들은 자신의 서비스에 직접 조정 코드를 추가하고 싶어할 수 있다. 이는 보다 엄격한 결합을 도입하고 개별 서비스를 신속하게 대체하기가 더 어렵기 때문에 피해야 한다.

단계 함수를 사용하여 각각 별개의 함수를 수행하는 개별 구성 요소에서 응용 프로그램을 작성할 수 있다. Step Functions는 오류 처리 및 직렬화/병렬화 등 서비스 조정의 복잡성을 숨기는 상태 시스템을 제공한다. 이를 통해 서비스 내부의 추가 조정 코드를 방지하면서 애플리케이션을 신속하게 확장하고 변경할 수 있다.
Step Functions는 구성요소를 조정하고 응용프로그램의 기능을 단계별로 수행할 수 있는 신뢰할 수 있는 방법이다. Step Functions는 일련의 단계로서 응용 프로그램의 구성 요소를 배열하고 시각화하는 그래픽 콘솔을 제공한다. 이를 통해 분산된 서비스를 구축하고 운영하는 것이 간단해진다.

<br>

### Distributed Monitoring

마이크로 서비스 아키텍처는 모니터링해야 하는 많은 다른 분산 부품으로 구성된다.
Amazon CloudWatch50을 사용하여 메트릭스를 수집 및 추적하고 로그 파일을 중앙 집중화 및 모니터링하고 경보를 설정하며 AWS 환경의 변화에 자동으로 대응할 수 있다. CloudWatch는 EC2 인스턴스, DynamoDB 테이블, RDS DB 인스턴스 등의 AWS 리소스뿐만 아니라 애플리케이션 및 서비스에서 생성된 사용자 정의 메트릭과 애플리케이션이 생성하는 모든 로그 파일을 모니터링할 수 있다.

모니터링
CloudWatch를 사용하여 리소스 활용도, 애플리케이션 성능 및 운영 상태에 대한 시스템 전반의 가시성을 확보하십시오. CloudWatch는 몇 분 이내에 사용할 수 있는 안정적이고 확장 가능하며 유연한 모니터링 솔루션을 제공한다. 더 이상 자체 모니터링 시스템과 인프라를 설정, 관리 및 확장할 필요가 없다. 마이크로 서비스 아키텍처에서는 개발자가 각 서비스에 대해 수집해야 할 메트릭스를 결정할 수 있기 때문에 CloudWatch를 사용하여 사용자 지정 메트릭스를 모니터링하는 기능이 추가적인 이점이 된다. 그 외에도, 사용자 지정 메트릭스를 기반으로 동적 확장을 구현할 수 있다.51

또 다른 인기 있는 선택사항은 특히 Amazon EKS–is가 Prometheus52를 사용하는 것이다. 프로메테우스는 수집된 지표를 시각화하기 위해 그라파나 53과 함께 자주 사용되는 공개 소스 감시 및 경보 툴킷이다. 많은 Kubernetes 구성요소는 측정지표를 /metrics에 저장하고 Prometheus는 이러한 측정지표를 정기적으로 스크래치할 수 있다.

로그 중앙 집중화
일관된 로깅은 문제를 해결하고 식별하는 데 매우 중요하다. 마이크로 서비스는 팀이 이전보다 더 많은 출시를 할 수 있도록 하고 엔지니어링 팀들이 생산의 새로운 기능에 대한 실험을 수행하도록 권장한다. 고객의 영향을 이해하는 것은 애플리케이션을 점진적으로 개선하는 데 매우 중요하다.

대부분의 AWS 서비스는 기본적으로 로그 파일을 중앙 집중화한다. AWS의 로그 파일의 주 대상은 Amazon S3와 Amazon CloudWatch Logs이다. EC2 인스턴스에서 실행 중인 애플리케이션의 경우, 로그 파일을 CloudWatch Logs로 보내는 데몬을 사용할 수 있다. Lambda 기능은 기본적으로 자신의 로그 출력을 CloudWatch Logs에 보내고 Amazon ECS는 컨테이너 로그를 CloudWatch Logs.54로 중앙 집중화할 수 있는 송수신 로그 드라이버를 지원하며 Amazon EKS의 경우 클러스터의 개별 인스턴스에서 중앙 집중식 로깅 CloudWatch Logs로 로그를 전달하는 FluentD를 실행할 필요가 있다. 여기서 Elasticsearch와 Kibana를 사용한 상위 수준의 보고를 위해 결합된다.

그림 10은 일부 서비스의 로깅 기능을 나타낸다. 팀은 Amazon Elasticsearch Service(Amazon ES)55 및 Kibana와 같은 도구를 사용하여 이러한 로그를 검색하고 분석할 수 있다. Amazon Athena56은 Amazon S3의 중앙 집중식 로그 파일에 대해 임시 쿼리를 실행하는 데 사용될 수 있다.



![aws](/posts/images/aws/aws-2020-03-17-10.jpg)
그림 10: AWS 서비스의 로깅 기능

분산 추적
많은 경우에, 일련의 마이크로 서비스는 요청을 처리하기 위해 함께 작용한다. 콜 체인의 서비스 중 하나에서 오류가 발생하는 수십 개의 마이크로 서비스로 구성된 복잡한 시스템을 상상해 보십시오. 모든 마이크로 서비스가 제대로 기록되고 중앙 시스템에 로그가 통합되어 있더라도 모든 관련 로그 메시지를 찾기는 어려울 수 있다.

AWS X-Ray57의 핵심 아이디어는 상관관계 ID의 사용으로, 특정 이벤트 체인과 관련된 모든 요청과 메시지에 부착된 고유한 식별자 입니다. 추적 ID는 요청이 첫 번째 X-Ray 통합 서비스(예: Application Load Balancer 또는 API Gateway)에 도달하여 응답에 포함된 경우 X-Amzn-Trace-Id라는 특정 추적 헤더의 HTTP 요청에 추가된다. X-Ray SDK를 통해 어떠한 마이크로 서비스도 이 헤더를 추가하거나 업데이트할 수 있다.

AWS X-Ray는 Amazon EC2, Amazon ECS, Lambda, AWS Elastic Beanstalk58과 함께 일한다. Java, Node.js 및 에 작성된 애플리케이션과 함께 X-Ray를 사용할 수 있다.이러한 서비스에 배포된 Net.



![aws](/posts/images/aws/aws-2020-03-17-11.jpg)

그림 11: AWS X선 서비스 맵

AWS 로그 분석 옵션
로그 데이터를 검색, 분석 및 시각화하는 것은 분산 시스템을 이해하는 중요한 측면이다. Amazon CloudWatch Logs Insights는 로그를 즉시 탐색, 분석 및 시각화할 수 있는 훌륭한 서비스입니다. 이를 통해 운영 문제를 해결할 수 있다. 로그 파일을 분석하는 또 다른 방법은 키바나와 함께 아마존 ES를 사용하는 것이다.

아마존 ES는 전체 텍스트 검색, 구조화된 검색, 분석 및 세 가지 모두를 조합하여 사용할 수 있다. 키바나는 아마존 ES를 위한 오픈 소스 데이터 시각화 플러그인으로, 그것과 원활하게 통합된다.

그림 12는 Amazon ES와 Kibana를 사용한 로그 분석을 보여준다. CloudWatch Logs는 CloudWatch Logs 구독을 통해 거의 실시간으로 로그 항목을 Amazon ES로 스트리밍하도록 구성할 수 있다. 키바나는 데이터를 시각화하고 아마존 ES의 데이터 저장소에 편리한 검색 인터페이스를 제공한다. 이 솔루션은 Elast와 같은 소프트웨어와 함께 사용할 수 있다.데이터에서 이상 징후, 스파이크 또는 기타 관심 패턴이 감지되는 경우, SNS 알림, 이메일, JIRA 티켓 생성 등을 전송하기 위한 경보 시스템 구현을 위한 경보59

![aws](/posts/images/aws/aws-2020-03-17-12.jpg)
그림 12: Amazon Elasticsearch Service 및 Kibana를 사용한 로그 분석

로그 파일 분석을 위한 또 다른 옵션은 Amazon QuickSight61과 함께 Amazon Redshift60을 사용하는 것이다.

Amazon QuickSight는 Amazon Redshift, Amazon RDS, Amazon Ourora, Amazon EMR, Amazon DynamoDB, Amazon S3 및 Amazon Kinesis를 포함한 AWS 데이터 서비스에 쉽게 연결될 수 있다.

Amazon CloudWatch Logs는 로그 데이터의 중앙 집중식 저장소 역할을 할 수 있으며, 데이터만 저장하는 것 외에, 로그 항목을 Amazon Kinesis Data Firehose로 스트리밍할 수 있다.

그림 13은 CloudWatch Logs와 Kinesis Data Firehose를 사용하여 로그 항목을 서로 다른 소스에서 Amazon Redshift로 스트리밍하는 시나리오를 보여준다. Amazon QuickSight는 분석, 보고 및 시각화를 위해 Amazon Redshift에 저장된 데이터를 사용한다.

![aws](/posts/images/aws/aws-2020-03-17-13.jpg)
그림 13: Amazon Redshift 및 Amazon QuickSight를 사용한 로그 분석

그림 14는 Amazon S3의 로그 분석 시나리오를 보여준다. 로그가 S3 버킷에 저장되면 로그 데이터를 Amazon Redshift나 Amazon EMR과 같은 다른 AWS 데이터 서비스에 로드하여 로그 스트림에 저장된 데이터를 분석하고 이상 징후를 찾을 수 있다.


![aws](/posts/images/aws/aws-2020-03-17-04.jpg)
그림 14: Amazon S3의 로그 분석

### Chattiness(잡담)

단일 애플리케이션을 작은 마이크로 서비스로 분리함으로써, 마이크로 서비스는 서로 대화해야 하기 때문에 통신 오버헤드가 증가한다. 많은 구현에서 REST over HTTP는 경량 통신 프로토콜이지만 높은 메시지 볼륨이 문제를 일으킬 수 있기 때문에 사용된다. 경우에 따라서는 많은 메시지를 주고받는 서비스를 통합하는 것을 고려할 수도 있다. 단지 잡담을 줄이기 위해 점점 더 많은 서비스를 통합하는 상황에 처한다면, 당신은 당신의 문제 도메인과 당신의 도메인 모델을 검토해야 한다.

프로토콜
이 백서의 앞부분에는 비동기 통신 및 경량 메시징 섹션에서 서로 다른 가능한 프로토콜이 설명되어 있다. 마이크로서비스의 경우 HTTP와 같은 간단한 프로토콜을 사용하는 것이 일반적이다. 서비스에 의해 교환되는 메시지는 JSON이나 YAML과 같이 사람이 읽을 수 있는 형식이나 Avro나 Protocol Buffers와 같은 효율적인 이진 형식과 같이 서로 다른 방식으로 인코딩될 수 있다.

캐싱
캐시는 마이크로 서비스 아키텍처의 지연 시간 및 잡담을 줄이는 좋은 방법이다. 실제 사용 사례와 병목현상에 따라 여러 개의 캐슁 계층이 가능하다. AWS에서 실행되는 많은 마이크로 서비스 애플리케이션은 Amazon ElastiCache를 사용하여 로컬에서 결과를 캐슁하여 다른 마이크로 서비스에 대한 통화량을 줄인다. API Gateway는 백엔드 서버의 로드를 줄이기 위해 내장된 캐싱 계층을 제공한다. 또한 캐싱은 데이터 지속성 계층에서 발생하는 부하를 줄이는 데도 유용하다. 캐싱 메커니즘의 과제는 양호한 캐시 적중률과 데이터의 적시성/일관성 사이에서 적절한 균형을 찾는 것이다.


### Auditing(감사)
수백 개의 분산된 서비스를 잠재적으로 가질 수 있는 마이크로서비스 아키텍처에서 다루어야 할 또 다른 과제는 각 서비스에 대한 사용자 작업의 가시성을 보장하고 조직 차원의 모든 서비스 전반에서 양호한 전체적인 시야를 확보할 수 있는 것이다. 보안 정책을 시행할 수 있도록 하기 위해, 시스템 변경을 초래하는 활동뿐만 아니라 자원 접근도 감사하는 것이 중요하다.
변경사항은 더 넓은 시스템에서 실행되는 서비스 전반뿐만 아니라 개별 서비스 수준에서 추적되어야 한다. 일반적으로 변경은

마이크로 서비스 아키텍처, 즉 감사 변경을 더욱 중요하게 만든다. 이 섹션에서는 마이크로 서비스 아키텍처를 감사하는 데 도움이 될 수 있는 AWS의 주요 서비스와 기능을 살펴본다.

감사내역
AWS CloudTrail62는 AWS Cloud에서 이루어지는 모든 API 호출을 실시간으로 기록하여 CloudWatch Logs 또는 Amazon S3에 몇 분 이내에 전송할 수 있기 때문에 마이크로 서비스의 변화를 추적하는 데 유용한 도구다.

모든 사용자 및 자동화된 시스템 동작은 검색이 가능해지고 예기치 않은 동작, 회사 정책 위반 또는 디버깅에 대해 분석할 수 있다. 기록된 정보에는 타임스탬프, 사용자/계정 정보, 호출된 서비스, 요청된 서비스 조치, 발신자의 IP 주소, 요청 매개변수와 응답 요소가 포함된다.

CloudTrail은 보안 관리자, 소프트웨어 개발자 또는 IT 감사자와 같은 다른 이해관계자가 자신의 추적 경로를 생성하고 관리할 수 있도록 하는 동일한 계정에 대한 다중 추적 정의를 허용한다. 마이크로 서비스 팀이 서로 다른 AWS 계정을 가지고 있다면, 하나의 S3 버킷으로 트랙을 집계하는 것이 가능하다.63

CloudWatch에서 감사 추적 정보를 저장하는 이점은 감사 추적 데이터가 실시간으로 캡처되고 검색 및 시각화를 위해 정보를 Amazon ES로 쉽게 재라우팅할 수 있다는 것이다. Amazon S3 및 CloudWatch 로그에 모두 로그인하도록 CloudTrail을 구성할 수 있다.

이벤트 및 실시간 작업
시스템 아키텍처의 특정 변경은 신속하게 대응되어야 하며 상황에 교정하기 위해 취한 조치 또는 변경을 승인하기 위한 특정 거버넌스 절차가 개시되어야 한다.

CloudWatch Events와 CloudTrail을 통합하면 모든 AWS 서비스에서 모든 돌연변이 API 호출에 대한 이벤트를 생성할 수 있다. 또한 정해진 스케줄에 따라 사용자 정의 이벤트를 정의하거나 이벤트를 생성할 수도 있다.

이벤트가 실행되어 정의된 규칙과 일치할 경우, 조직의 적절한 담당자에게 즉시 알릴 수 있으므로 적절한 조치를 취할 수 있다. 필요한 작업을 자동화할 수 있는 경우 규칙은 자동으로 내장 워크플로우를 트리거하거나 Lambda 함수를 호출하여 문제를 해결할 수 있다.

그림 15는 CloudTrail과 CloudWatch Events가 협력하여 마이크로 서비스 아키텍처 내의 감사 및 교정 요구 사항을 해결하는 환경을 보여준다. 모든 마이크로 서비스는 CloudTrail에 의해 추적되고 감사 추적은 S3 버킷에 저장된다. CloudWatch 이벤트(CloudTrail)는 CloudTrail의 맨 위에 위치하며 아키텍처가 특정 변경될 때 경고를 트리거한다.

![aws](/posts/images/aws/aws-2020-03-17-15.jpg)
그림 15: 감사 및 업데이트 적용

리소스 인벤토리 및 변경 관리
신속한 변화를 위한 개발 환경에서 빠르게 변화하는 인프라 구성에 대한 제어력을 유지하려면 아키텍처 감사 및 제어를 위해 보다 자동화되고 관리되는 접근 방식을 보유하는 것이 필수적이다.

CloudTrail 및 CloudWatch Events는 마이크로 서비스 전반에 걸친 인프라 변경을 추적하고 대응하기 위한 중요한 구성 요소지만, AWS Config64 규칙은 회사가 자동으로 정책 위반을 탐지, 추적 및 경고하는 특정 규칙을 가진 보안 정책을 정의할 수 있도록 해준다.

다음 예는 마이크로 서비스 아키텍처 내에서 비준수 구성 변경을 탐지, 통보 및 자동으로 대응하는 방법을 보여 준다. 개발 팀의 일원이 API 게이트웨이를 변경하여 엔드포인트가 HTTPS 요청만 허용하는 것이 아니라 인바운드 HTTP 트래픽을 허용하도록 하였다.

이 상황은 이전에 보안으로 식별되었기 때문에

조직의 컴플라이언스 문제, AWS Config 규칙이 이미 이 상태를 모니터링하고 있음.

이 규칙은 변경 사항을 보안 위반으로 식별하고, 감사를 위해 S3 버킷에 탐지된 변경 사항에 대한 로그를 생성하고, SNS 알림을 생성하는 두 가지 작업을 수행한다. Amazon sns는 우리의 시나리오에서 두 가지 목적으로 사용된다: 보안 위반에 대해 알리기 위해 특정 그룹에 이메일을 보내는 것과 SQS 대기열에 메시지를 추가하는 것이다. 다음으로 메시지가 선택되고 API Gateway 구성을 변경하여 준수 상태가 복원된다.

![aws](/posts/images/aws/aws-2020-03-17-16.jpg)
그림 16: AWS 구성을 통한 보안 위반 탐지

<br>

## Conclusion

마이크로서비스 아키텍처는 전통적인 단일 아키텍처의 한계를 극복하기 위한 분산 설계 접근방식이다. 마이크로 서비스는 애플리케이션과 조직을 확장하는 동시에 주기 시간을 단축하는 데 도움이 된다.

그러나 이들은 또한 추가적인 아키텍처 복잡성과 운영 부담을 가중시킬 수 있는 몇 가지 과제를 안고 있다.

AWS는 제품 팀이 마이크로 서비스 아키텍처를 구축하고 아키텍처 및 운영 복잡성을 최소화할 수 있도록 지원하는 광범위한 관리 서비스 포트폴리오를 제공한다. 이 백서에서는 관련 AWS 서비스와 AWS 서비스를 통해 서비스 검색 또는 이벤트 소싱과 같은 일반적인 패턴을 구현하는 방법을 안내한다.

<br>

## Contributors
다음 개인과 단체가 이 문서에 기여했다.
- Sascha Möllering, 솔루션 아키텍처, AWS
- 크리스찬 뮐러, 솔루션 아키텍처, AWS
- 솔루션 아키텍처, AWS, Matthias Jung
- Peter Dalbhanjan, 솔루션 아키텍처, AWS
- Peter Chapman, 솔루션 아키텍처, AWS
- Christop Kassen, 솔루션 아키텍처, AWS

<br>

---
### :bookmark_tabs: 참조(references)
- [https://d1.awsstatic.com/whitepapers/microservices-on-aws.pdf](https://d1.awsstatic.com/whitepapers/microservices-on-aws.pdf)
